{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "import numpy as np\n",
    "import math\n",
    "from xml.etree import ElementTree\n",
    "from contextlib import contextmanager\n",
    "import threading\n",
    "from google.colab import output\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install Go\n",
    "\n",
    "!add-apt-repository ppa:longsleep/golang-backports -y\n",
    "!apt update\n",
    "!apt install golang-go\n",
    "%env GOPATH=/root/go\n",
    "!go get -u github.com/gopherdata/gophernotes\n",
    "!cp ~/go/bin/gophernotes /usr/bin/\n",
    "!mkdir /usr/local/share/jupyter/kernels/gophernotes\n",
    "!cp ~/go/src/github.com/gopherdata/gophernotes/kernel/* \\\n",
    "       /usr/local/share/jupyter/kernels/gophernotes\n",
    "\n",
    "# then refresh notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install AuGoment\n",
    "! git clone https://github.com/lootag/ImageAuGomentationCLI.git\n",
    "os.chdir('ImageAuGomentationCLI' + os.sep + 'src')\n",
    "! make\n",
    "os.chdir('/content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mean_average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/guglielmoG/windspeed.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from windspeed.utils import *\n",
    "\n",
    "repo = 'windspeed'\n",
    "detection_classes = ['flag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO_DELETE\n",
    "Possiamo mettere legacy code che non ha senso stia da altre parti ma che potrebbe essere utile in futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use to rename pictures\n",
    "with cwd('windspeed', 'flags'):\n",
    "    # get all annots\n",
    "    ann = set(os.listdir('Annotations'))\n",
    "    c = 0\n",
    "    for f in os.listdir('images'):\n",
    "        img_name, ext = os.path.splitext(f)\n",
    "        if os.path.exists(join_path('Annotations', img_name+'.xml')):\n",
    "            os.rename(join_path('Annotations', img_name+'.xml'), join_path('Annotations', str(c) + 'flag.xml'))\n",
    "            os.rename(join_path('images', f), join_path('images', str(c)+'flag'+ext))\n",
    "            ann.remove(img_name+'.xml')\n",
    "        else:\n",
    "            os.rename(join_path('images', f), f)\n",
    "            print(f)\n",
    "        c += 1\n",
    "            \n",
    "    print('No images for ', ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to debug augoment, identify images for which creates problems\n",
    "with cwd(repo):\n",
    "    ! git checkout .\n",
    "    ! git clean -fd\n",
    "\n",
    "with cwd(repo, 'data', 'flags'):\n",
    "    os.mkdir('temp')\n",
    "    os.mkdir(join_path('temp', 'Images'))\n",
    "    os.mkdir(join_path('temp', 'Annotations'))\n",
    "    c = 0\n",
    "    for f in os.listdir('Images'):\n",
    "        img_name,_ = os.path.splitext(f)\n",
    "        os.rename(join_path('Annotations', img_name+'.xml'), join_path('temp', 'Annotations', img_name+'.xml'))\n",
    "        os.rename(join_path('Images', f), join_path('temp', 'Images', f))\n",
    "        try:\n",
    "            with cwd('temp'):\n",
    "                ! augoment -exclusion_threshold=1 -batch_size=1 -blur=2 >good 2>bad\n",
    "                ! echo {f} > boh\n",
    "                ! grep panic bad >> boh\n",
    "                tt = ! grep panic bad\n",
    "                if len(tt) != 0:\n",
    "                    ! cat boh >> out_good\n",
    "                    ! echo \"\" >> out_good\n",
    "        except Exception as e:\n",
    "            print(f, str(e))\n",
    "        finally:\n",
    "            os.remove(join_path('temp', 'Annotations', img_name+'.xml'))\n",
    "            os.remove(join_path('temp', 'Images', f))\n",
    "        print(c)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END_TO_DELETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag Detection\n",
    "\n",
    "Folder structure:  \n",
    "-train  \n",
    "-validation  \n",
    "-test  \n",
    "\n",
    "In each folder one can find images and annotations, separated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Folder Structure Creation\n",
    "Divide in training, validation and test set, with approximately 75%, 15% and 10% respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3456)\n",
    "\n",
    "def make_augoment_dir(name):\n",
    "    os.mkdir(name)\n",
    "    os.mkdir(join_path(name, 'Images'))\n",
    "    os.mkdir(join_path(name, 'Annotations'))\n",
    "    \n",
    "with cwd(repo, 'data', 'flags'):\n",
    "    make_augoment_dir('train')\n",
    "    make_augoment_dir('valid')\n",
    "    make_augoment_dir('test')\n",
    "    imgs = os.listdir('Images')\n",
    "    n = len(imgs)\n",
    "    #use random indexes to shuffle the images\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    for i in range(n):\n",
    "        img = imgs[idx[i]]\n",
    "        img_name, _ = os.path.splitext(img)\n",
    "        if i < n * 0.75:\n",
    "            os.rename(join_path('Images', img), join_path('train', 'Images', img))\n",
    "            os.rename(join_path('Annotations', img_name + '.xml'), join_path('train', 'Annotations', img_name + '.xml'))\n",
    "        elif i < n * 0.9:\n",
    "            os.rename(join_path('Images', img), join_path('valid', 'Images', img))\n",
    "            os.rename(join_path('Annotations', img_name + '.xml'), join_path('valid', 'Annotations', img_name + '.xml'))\n",
    "        else:\n",
    "            os.rename(join_path('Images', img), join_path('test', 'Images', img))\n",
    "            os.rename(join_path('Annotations', img_name + '.xml'), join_path('test', 'Annotations', img_name + '.xml'))\n",
    "    os.rmdir('Images')\n",
    "    os.rmdir('Annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation\n",
    "NB: if one would like to obtain different blur values for a given image (i.e. produce say 3 new blurred images out of every image, with different blur values), they would need to rename previosly created blurred images, because they are overwritten.\n",
    "\n",
    "Convert images to jpg for augoment to work properly, then run augoment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_jpg(join_path(repo,'data','flags','train', 'Images'))\n",
    "convert_to_jpg(join_path(repo,'data','flags','valid', 'Images'))\n",
    "convert_to_jpg(join_path(repo,'data','flags','test', 'Images'))\n",
    "\n",
    "with cwd(join_path(repo,'data','flags','train')):\n",
    "    ! augoment -blur=2\n",
    "    \n",
    "with cwd(join_path(repo,'data','flags','valid')):\n",
    "    ! augoment -blur=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO Preprocessing\n",
    "\n",
    "Clone the repo, and compile code with CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone https://github.com/pjreddie/darknet.git\n",
    "\n",
    "with cwd('darknet'):\n",
    "    ! sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "    ! sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "    ! make\n",
    "    \n",
    "#copy needed files\n",
    "os.rename(join_path('darknet', 'darknet'), join_path(repo, 'darknet'))\n",
    "os.mkdir(join_path(repo, 'backup'))\n",
    "os.mkdir(join_path(repo, 'results'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert annotations from xml to YOLO format. Additionally, create input txt files containing images paths, as required by YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_img_path(in_dir, out_path):\n",
    "    l = glob.glob(join_path(in_dir, '*[!.txt]'))\n",
    "    with open(out_path, 'w') as w:\n",
    "        w.write('\\n'.join(l))\n",
    "        \n",
    "#converting annotations\n",
    "with cwd(repo, 'data', 'flags'):\n",
    "    for f in os.listdir(): #train, valid, test\n",
    "        if os.path.isdir(f) and f in ['train', 'valid']:\n",
    "            for xml in os.listdir(join_path(f, 'AugmentedAnnotations')):\n",
    "                convert_annot_yolo(join_path(f, 'AugmentedAnnotations', xml), detection_classes, join_path(f, 'AugmentedImages'))\n",
    "\n",
    "#creating input paths to images\n",
    "with cwd(repo):\n",
    "    collect_img_path(join_path('data','flags','train','AugmentedImages'), join_path('data','flags','train.txt'))\n",
    "    collect_img_path(join_path('data','flags','valid','AugmentedImages'), join_path('data','flags','valid.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of _cfg/flag.data_ is as follows\n",
    "```\n",
    "  classes = 1\n",
    "  train  = <path-to-data>/train.txt\n",
    "  valid  = <path-to-data>/valid.txt\n",
    "  names = <path-to-data>/flag.names\n",
    "  backup = /mydrive/yolov3\n",
    "```\n",
    "_flag.names_ should contain the list of classes, one per line.  \n",
    "\n",
    "Download weights for the classifier (Darknet-53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://pjreddie.com/media/files/darknet53.conv.74\n",
    "os.rename('darknet53.conv.74', join_path(repo,'cfg','darknet53.conv.74'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the cfg file for _yolo-v3_. Need to set adeguate `batch` (number of images per training step) and `subdivisions` (further subdivide the batch to speedup training) values according to the hardware at disposal. Then need to update `classes` in yolo layer to match the number of classes that needs to be predicted. Finally, adjust `filters` amount in convolutional layer prior to yolo layer, to match the updated number of classes, according to the formula:\n",
    "```\n",
    "filters = (classes + 5)*3\n",
    "```\n",
    "The file _yolo-v3.cfg_ provided is already setup in such a way.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount('/content/gdrive')\n",
    "! ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
    "! mkdir -p \"/mydrive/yolov3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean():\n",
    "    output.clear()\n",
    "\n",
    "#clean every minute, for 12 hours\n",
    "for x in range(20,1*60*60*12,60):\n",
    "    timer = threading.Timer(x, clean)\n",
    "    timer.start()\n",
    "\n",
    "with cwd(repo):\n",
    "    ! chmod 755 darknet\n",
    "    ! ./darknet detector train cfg/flag.data cfg/yolov3.cfg cfg/darknet53.conv.74 -dont_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We start by importing our trained model into opencv. To predict we can use`predict_yolo()`, which takes as input the network, and image, and predicts and returns the bounding boxes. They are encoded with one bounding box per row, represented as `center_x, center_y, w, h, confidence` where `center_x, center_y` are the center pixels of the bounding box, `w` and `h` are half of the width and half of the height respectively. Finally, `confidence` stands for the prediction confidence of the network.\n",
    "\n",
    "At this stage we are interested in assessing the quality of our model out of sample, computing the mAP. To do that we use a wrapper function that takes a generic model, custom predict function for that model, class labels and image folder, and computes the metric of interest. As for the optional parameters, we are asking to compute mAP according to both pascal_voc definiton and COCO. Finally, `net_input` refers to the image input size fo YOLO, as specified in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp /mydrive/yolov3/yolov3.backup /content\n",
    "os.rename('yolov3.backup', join_path(repo, 'cfg', 'volov3.weights'))\n",
    "\n",
    "with cwd(repo, 'cfg'):\n",
    "    net = cv2.dnn.readNet(\"volov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = net.getUnconnectedOutLayersNames()\n",
    "\n",
    "mAP = evaluate_model(net, predict_yolo, detection_classes, mdl_type='detection', \n",
    "                     path=join_path(repo,'data','flags','test'),\n",
    "                     mAP_type='both', net_input_w=608, net_input_h=608)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
